# Retrieving and visualising data

## Multi-step data analysis
* Bring everything together
* Use two databases
    * Collect raw data
    * Clean and store data

## Many data mining technologies
* Hadoop
* Spark
* Redshift

## "Personal Data Mining"
* Our goal is to make you better programmers - not to make you data mining experts

## GeoData
* Makes a Google Map from user entered data
* Uses the Google Geodata API
* Caches data in a database to avoid rate limiting and allow restarting
* Visualised in a browser using the Google Maps API

## Page Rank
* Write a simple web page crawler
* Compute a simple version of Google's Page Rank algorithm
* Visualise the resulting network

## Web crawler
* A web crawler is a computer program that browses the world wide web in a methodical, automated manner. Web crawlers are mainly used to create a copy of all the visited pages for later processing by a search enginer that will index the downloaded pages to provide fast searches.

## Process
* Retrieve a page
* Look through the page for links
* Add the links to a list of "to be retrieved" sites
* Repear...

## Web crawling policy
* A selection policy that states which pages to download
* A re-visit policy that states when to check for changes to the pages
* A politeness policy that states how to avoid overloading websites
* A parallelisation policy that states how to coordinate distributed web crawlers

## robots.txt
* A way for a web site to communicate with web crawlers
* An informal and voluntary standard
* Sometimes folks make a "Spider Trap" to catch "bad" spiders

## Google Architecture
* Web crawling
* Index Building
* Searching

## Search Indexing
Search engine indexing collects, parses and stores data to facilitate fast and accurate information retrieval. The purpose of storing an index is to optimise speed and performance in finding relevant documents for a search query. Without an index, the search engine would scan every document in the corpus, which would require considerable time and computing power.

## Mailing Lists - Gmane
* Crawl the archive of a mailing list
* Do some analysis/cleanup
* Visualise the data as word cloud and lines

## Warning: This dataset is > 1GB
* Do not point this application at gmane.org and let it run
* There is no rate limits - these are cool folks
* Use dr-chucks version
* `http://mbox.dr-chuck.net/sakai.devel/4/5`

